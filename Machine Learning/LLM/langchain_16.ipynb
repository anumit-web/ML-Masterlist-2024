{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anumit-web/python-interview-2024/blob/main/machine%20learning/Unsupervised_Learning_clustering_type_iris_flower_clustering_Gaussian_mixture_model_(GMM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_lhvb-UXLbF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomuVIUl9uY6"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Shee7JuzVF"
      },
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt templates\n",
        "\n",
        "# web page summary\n",
        "\n",
        "# ChatPromptTemplate"
      ],
      "metadata": {
        "id": "99VCqplEvvAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating PromptTemplate with LLMs"
      ],
      "metadata": {
        "id": "8XwHCnNavxns"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow1vTaKl9oHQ"
      },
      "source": [
        "# Chapter 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko4QaixAfPyF"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKa4SWV84DMv"
      },
      "source": [
        "# Python Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "3pRBaqLz9atZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFXpB4wv-5-1",
        "outputId": "2b0f98c9-f75e-42c2-8f9d-95853f78af3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0djESK29att",
        "outputId": "e73a0146-86fb-4ba1-89cc-61a4ea4672ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello, World!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "nfFMli_AEOK2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "96aff1cb-2e43-427a-87ac-51e70a9735f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2024-11-15  16:45'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "tz = timezone('EST')\n",
        "datetime.now(tz).strftime(\"%Y-%m-%d  %H:%M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjDoARvnvU2L"
      },
      "source": [
        "---\n",
        "---\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR391vUc7l-N"
      },
      "source": [
        "# Python code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkfbOedi1WHO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "1SZd9nC1wLm3"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import langchain\n",
        "except:\n",
        "  !pip install langchain\n",
        "  import langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "4iCA0l5hxjB8"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-community langchain-core --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "0n5IXOCNxppN"
      },
      "outputs": [],
      "source": [
        "# ! pip install --upgrade langchain --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install -qU langchain-openai --quiet"
      ],
      "metadata": {
        "id": "_zVBLvkpHoUY"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "AWiheCyd1Yc0"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-cohere --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install langchain-huggingface --quiet"
      ],
      "metadata": {
        "id": "z_eJLyvxN3ax"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "A0RW7lT_UxHE"
      },
      "outputs": [],
      "source": [
        " ! pip install --upgrade --quiet tiktoken langchain langgraph beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "01GEQvpTUyyp"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-core langgraph>0.2.27 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Ck7bfWqemvdt"
      },
      "outputs": [],
      "source": [
        "# ! pip install langchain-huggingface --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3vL9TN8TWuj"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "wEst9m_R1ZPy"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = \"Q6nIsqJ4FX9XcZwlcQLSzA06z0oXYAGBw0jmCdbE\"\n",
        "\n",
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus\")\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus-08-2024\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "openai_api_key = \"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\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm_model2 = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "llm_model2 = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "llm_model2 = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"
      ],
      "metadata": {
        "id": "0fWLusbOG27J"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "Nv_mwGwkrlIh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqthzTFPZsvU"
      },
      "source": [
        "# Prompt tables in ChatGPT\n",
        "# we use Cohere instead of chatgpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljt5T8yPjYeq"
      },
      "source": [
        "# This is NOT working ❌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_VXS7tTjS4Y"
      },
      "source": [
        "# This is working ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "I7JxAG-Cf3A4",
        "outputId": "ffe77dbb-ddc2-440d-f0d3-051f238b4133"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">10 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "count = 10\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">10 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbrN-0pu5L3I"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "count = count + 10\n",
        "counter_var = '<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">'+ str(count) + \"&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>\"\n",
        "display(HTML(counter_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "sojZoCdw59fF",
        "outputId": "32e81061-bf1f-4a33-8350-244289499c9c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">20&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into French\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "output = llm_model.invoke(messages)\n",
        "\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPhryIPb6KOv",
        "outputId": "e4dd84d7-1b1b-42a1-fb1b-02b4f8488e80"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonjour ! Comment puis-je vous aider aujourd'hui ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = count + 10\n",
        "counter_var = '<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">'+ str(count) + \"&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>\"\n",
        "display(HTML(counter_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "EF8Gliua9Hs6",
        "outputId": "b9fb6d0e-5323-4562-9f0f-5bae397a6401"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">30&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "m-ifyjPA6Fxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "_J_WqtVB6LvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dummy"
      ],
      "metadata": {
        "id": "L4Zt9P7SdFon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = count + 10\n",
        "counter_var = '<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">'+ str(count) + \"&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>\"\n",
        "display(HTML(counter_var))"
      ],
      "metadata": {
        "id": "WkMdnrjm4R13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "ec36da55-6aef-414f-f741-12e40848dbe0"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">40&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = count + 10\n",
        "counter_var = '<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">'+ str(count) + \"&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>\"\n",
        "display(HTML(counter_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "2OfM3Jawd-FJ",
        "outputId": "47c68ca9-4d04-4ffe-edcb-98f2df020190"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">50&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "count = count + 10\n",
        "counter_var = '<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">'+ str(count) + \"&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>\"\n",
        "display(HTML(counter_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "vl_IDNkQeBAV",
        "outputId": "b1509b41-d4be-4d32-84f1-4c12d3259935"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">60&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = \"Q6nIsqJ4FX9XcZwlcQLSzA06z0oXYAGBw0jmCdbE\"\n",
        "\n",
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus\")\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus-08-2024\")"
      ],
      "metadata": {
        "id": "3hpmdqT3w6LZ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "OwQSOcpeweGr"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into French\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "# Define prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\"),\n",
        "        (\"human\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")\n",
        "\n",
        "     ]\n",
        ")\n",
        "\n",
        "# Instantiate chain\n",
        "chain = create_stuff_documents_chain(llm_model, prompt)\n",
        "\n",
        "# Invoke chain\n",
        "result = chain.invoke({\"context\": docs})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQpaw8rmxPsI",
        "outputId": "d7a13588-35a5-4663-dff1-2b5814fe3b15"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This article explores the potential of building autonomous agents with Large Language Models (LLMs) as their core controller. It highlights several proof-of-concept demos, such as AutoGPT, GPT-Engineer, and BabyAGI, which demonstrate the versatility of LLMs beyond text generation. The article discusses key components of an LLM-powered agent system, including planning, memory, and tool use. It also covers various techniques for task decomposition, self-reflection, and memory management, as well as the use of external tools to enhance the agent's capabilities. The article concludes by addressing some common challenges in building LLM-centered agents, such as finite context length, long-term planning, and the reliability of the natural language interface.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (Anaconda)",
      "language": "python",
      "name": "anaconda3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}