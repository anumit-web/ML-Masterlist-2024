{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anumit-web/python-interview-2024/blob/main/machine%20learning/Unsupervised_Learning_clustering_type_iris_flower_clustering_Gaussian_mixture_model_(GMM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomuVIUl9uY6"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Shee7JuzVF"
      },
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample questions to chatgpt\n",
        "# ( Cohere actually )"
      ],
      "metadata": {
        "id": "LwzJlqIJGq8p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow1vTaKl9oHQ"
      },
      "source": [
        "# Chapter 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko4QaixAfPyF"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKa4SWV84DMv"
      },
      "source": [
        "# Python Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "3pRBaqLz9atZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFXpB4wv-5-1",
        "outputId": "1e4f3d85-ce82-437e-b601-4f140b503f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0djESK29att",
        "outputId": "59534281-6c31-455c-d078-869f6870dcb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello, World!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "nfFMli_AEOK2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjDoARvnvU2L"
      },
      "source": [
        "---\n",
        "---\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR391vUc7l-N"
      },
      "source": [
        "# Python code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkfbOedi1WHO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1SZd9nC1wLm3"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import langchain\n",
        "except:\n",
        "  !pip install langchain\n",
        "  import langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "4iCA0l5hxjB8"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-community langchain-core --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "0n5IXOCNxppN"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade langchain --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "AWiheCyd1Yc0"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-cohere --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "A0RW7lT_UxHE"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade --quiet tiktoken langchain langgraph beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "01GEQvpTUyyp"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-core langgraph>0.2.27 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Ck7bfWqemvdt"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-huggingface --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3vL9TN8TWuj"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "wEst9m_R1ZPy"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = \"Q6nIsqJ4FX9XcZwlcQLSzA06z0oXYAGBw0jmCdbE\"\n",
        "\n",
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus\")\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus-08-2024\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "Nv_mwGwkrlIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ask chatgpt some simple questions"
      ],
      "metadata": {
        "id": "W8hC6hmiHeIl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljt5T8yPjYeq"
      },
      "source": [
        "# This is NOT working ❌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_VXS7tTjS4Y"
      },
      "source": [
        "# This is working ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "I7JxAG-Cf3A4",
        "outputId": "6697d16c-c3a7-4c71-eabd-44dc85843fac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">10 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">10 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOQ5VpBMf0p7",
        "outputId": "ee8d8368-1bfd-4856-e21f-c13343185553"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hello Bob! I'm Command, an AI assistant chatbot. How can I help you today?\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b3117db3-1549-46e0-bb71-dcd795fa86d0', 'token_count': {'input_tokens': 211.0, 'output_tokens': 19.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b3117db3-1549-46e0-bb71-dcd795fa86d0', 'token_count': {'input_tokens': 211.0, 'output_tokens': 19.0}}, id='run-2caf6d46-c3c5-42a8-aacd-2d87a449b64a-0', usage_metadata={'input_tokens': 211, 'output_tokens': 19, 'total_tokens': 230})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "llm_model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "O9igLhYQrOy7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "A48k1GtKf2fZ",
        "outputId": "2cc81572-d737-4b54-f6de-d6e4314283b7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">20 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">20 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Hello\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "output = llm_model.invoke(messages)"
      ],
      "metadata": {
        "id": "_VweEJaMrNrz"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSLssFkIIefr",
        "outputId": "1261cabc-ec85-4f5d-878e-130583a733f3"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='Hello! How can I help you today?' additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b3474a45-83f7-46f0-afe6-90a2eec1d59a', 'token_count': {'input_tokens': 212.0, 'output_tokens': 9.0}} response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': 'b3474a45-83f7-46f0-afe6-90a2eec1d59a', 'token_count': {'input_tokens': 212.0, 'output_tokens': 9.0}} id='run-9b9d509a-e555-4c33-b4eb-9e9611cb4bad-0' usage_metadata={'input_tokens': 212, 'output_tokens': 9, 'total_tokens': 221}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeLkQrGOI6fu",
        "outputId": "afc467f2-7a92-4960-939b-8c8c65be0283"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSOTr5G823HI"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "vm90Ho2Xi1qO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "6271601a-327b-4c2e-d8d7-c6da049363c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">50 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">50 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"Hello\"),\n",
        "    HumanMessage(content=\"Write a minute-long script for an advertisement about selling hotdog\"),\n",
        "]\n",
        "\n",
        "output = llm_model.invoke(messages)\n",
        "\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okYTogwqKiPB",
        "outputId": "180b90e6-58d3-4a6e-ebd3-a2b88977f0a0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Opening shot of a vibrant street food stand with a large 'HOTDOGS' sign]\n",
            "\n",
            "Narrator (energetic voice): \"Are you ready to spice up your day? It's time to indulge in the ultimate street food sensation!\"\n",
            "\n",
            "[Cut to a close-up of a hotdog sizzling on the grill]\n",
            "\n",
            "Narrator: \"Introducing the hottest dogs in town! [Brand Name] brings you the perfect blend of juicy flavors.\"\n",
            "\n",
            "[Show a chef quickly adding various toppings on a hotdog]\n",
            "\n",
            "Narrator: \"From the classic ketchup and mustard to the exotic toppings, we've got it all! Savour the crispy bite of our grilled buns and the explosion of tastes in every bite.\"\n",
            "\n",
            "[Quick cuts showing different people enjoying hotdogs]\n",
            "\n",
            "Narrator: \"Whether it's a quick bite on the go or a fun family treat, our hotdogs are the ultimate crowd-pleaser. Don't wait; satisfy your cravings today!\"\n",
            "\n",
            "[Display the brand logo and contact information]\n",
            "\n",
            "Narrator: \"Find us at [location] or order online. Get your sizzle on with [Brand Name] hotdogs! Indulge now!\"\n",
            "\n",
            "[End with a catchy background music beat]\n",
            "\n",
            "[Duration: 1 minute]\n",
            "\n",
            "This script sets the tone for a fun and enticing advertisement, showcasing the appeal of hotdogs with a focus on taste and variety. It can be further adapted to include specific offers or additional visuals to capture the audience's attention.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d9BgjVei01c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbrN-0pu5L3I"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">60 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "zPT3RDxMLVAU",
        "outputId": "294b1ed7-322d-4bbe-b2c2-4a7047df4215"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">60 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"Hello\"),\n",
        "    HumanMessage(content=\"hi\"),\n",
        "]\n",
        "\n",
        "output = llm_model.invoke(messages)\n",
        "\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtQSbOFgLZRp",
        "outputId": "750f3300-bce8-4c3a-a6fd-4b355fde5a22"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fC0vg4rdMYbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CQCtTdMfMZLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">60 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ],
      "metadata": {
        "id": "gOhd9CI3Mdd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"Hello\"),\n",
        "    HumanMessage(content=\"I want to create an agenda for a meeting about missed deadlines with my team. Can you give me some examples of what should be included?\"),\n",
        "]\n",
        "\n",
        "output = llm_model.invoke(messages)\n",
        "\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4FoAlsuMfLP",
        "outputId": "bf207c49-8408-45d5-d33d-850ba309daf6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, creating an agenda for a meeting to discuss missed deadlines is a great way to structure the conversation and ensure a productive outcome. Here are some items you might want to include:\n",
            "\n",
            "- **Meeting Introductions and Objectives:** Begin by welcoming the team and clearly stating the purpose of the meeting. For example, \"Today, we will discuss the recent trend of missed deadlines and find solutions to improve our project management.\"\n",
            "\n",
            "- **Review of Missed Deadlines:** Provide a summary of the projects or tasks that have been affected by missed deadlines. Share relevant data, such as the number of missed deadlines, the projects involved, and the potential impact on clients or company goals. \n",
            "\n",
            "- **Root Cause Analysis:** Facilitate a discussion to identify the reasons behind the missed deadlines. This could include:\n",
            "   - Overcommitment of resources: Discuss if team members are taking on more work than they can handle and the impact of this on deadlines.\n",
            "   - Lack of communication: Encourage team members to share their experiences and identify any communication gaps that may have led to delays.\n",
            "   - Ineffective time management: Explore whether individuals are struggling with time estimation or prioritization.\n",
            "   - Resource constraints: Identify if the team lacks the necessary tools, software, or external resources to complete tasks efficiently.\n",
            "   - Unforeseen challenges: Discuss any unexpected obstacles that arose during projects.\n",
            "\n",
            "- **Brainstorming Solutions:** Collaboratively work on finding solutions to prevent future deadline misses. Some points to consider:\n",
            "   - Task Prioritization: Develop strategies to prioritize tasks and projects based on their urgency and importance.\n",
            "   - Resource Allocation: Discuss how to allocate resources more effectively, ensuring that team members are not overburdened.\n",
            "   - Communication Protocols: Establish clear communication guidelines, including regular check-ins and progress updates.\n",
            "   - Project Planning: Emphasize the importance of realistic project planning and the need for contingency plans.\n",
            "   - Time Management Training: Consider providing training or resources to help team members improve their time management skills.\n",
            "\n",
            "- **Action Item Assignment:** Based on the solutions discussed, assign specific action items to team members. This could include implementing new processes, conducting training sessions, or creating a task force to address the issues.\n",
            "\n",
            "- **Accountability and Follow-up:** Establish a system to monitor progress and hold team members accountable for their assigned tasks. Schedule follow-up meetings to review the effectiveness of the implemented solutions.\n",
            "\n",
            "- **Open Discussion and Feedback:** Allow time for team members to share their thoughts, concerns, or suggestions. Encourage open communication and feedback to ensure everyone feels involved in the process.\n",
            "\n",
            "- **Meeting Summary and Next Steps:** Wrap up the meeting by summarizing the key points, decisions made, and action items. Provide a clear overview of what will happen next and any deadlines associated with the assigned tasks.\n",
            "\n",
            "Remember to keep the agenda focused and allow sufficient time for discussion and problem-solving. It's essential to create a safe and non-judgmental environment during the meeting to encourage honest and constructive conversations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s10saumTMf2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ZQOF9smBNOXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">80 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "KWR8VsM_Mglu",
        "outputId": "2c3d8ce2-ee6f-4c03-f1a6-e398006694d1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">80 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"Hello\"),\n",
        "    HumanMessage(content=\"What factors should I consider when quoting for a brand deal with a candle company, and what ballpark range should I charge? The scope is to post 3 videos on TikTok, and I have 100,000 followers.\"),\n",
        "]\n",
        "\n",
        "output = llm_model.invoke(messages)\n",
        "\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK70vyIpMhHj",
        "outputId": "ea1bf4a8-628e-4241-9b57-a494bb5f961c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When negotiating a brand deal with a candle company for posting promotional videos on TikTok, several factors can influence the pricing and terms of the collaboration. Here are some key considerations:\n",
            "\n",
            "**1. Engagement and Reach:**\n",
            "   - Follower Count: Having 100,000 followers is an excellent starting point for attracting brand collaborations. However, it's not just about the numbers; the engagement rate is crucial. Higher engagement indicates that your audience is responsive and interactive, making your content more valuable to brands.\n",
            "   - Audience Demographics: Understand the demographics of your audience (age, gender, location, interests) and how well they align with the candle company's target market. If your audience matches their target demographic, your content will likely have a more significant impact, allowing you to negotiate a higher rate.\n",
            "\n",
            "**2. Content Creation and Usage:**\n",
            "   - Number of Videos: You've mentioned creating three videos, but consider the effort and resources required for each video. Will these be simple product showcases or more elaborate productions? The complexity and time investment in content creation can impact your pricing.\n",
            "   - Usage Rights: Discuss with the company whether they want exclusive rights to the content, how long they intend to use the videos, and on which platforms. If they request extended usage rights or plan to repurpose the content for other campaigns, you can charge a premium.\n",
            "\n",
            "**3. Market Rates and Benchmarking:**\n",
            "   - Influencer Rates: Research the current market rates for influencer marketing in your region and niche. Rates can vary widely depending on the platform, engagement rate, and the influencer's reputation. According to various sources, TikTok influencers with 100,000 followers can charge anywhere from $200 to $1,000 per post, with some even charging more for highly engaging content.\n",
            "   - Industry Benchmarks: Look for similar brand deals within the candle or home fragrance industry to get an idea of the going rate. Check if there are any industry-specific influencer marketing reports or surveys that provide pricing insights.\n",
            "\n",
            "**4. Performance Metrics and Guarantees:**\n",
            "   - Performance-based Pricing: If your content consistently drives high engagement or conversions, you can propose a performance-based pricing model. For instance, you could negotiate a base fee plus a bonus for achieving specific metrics, such as a certain number of views, likes, or sales generated through a unique discount code.\n",
            "\n",
            "**5. Exclusivity and Timing:**\n",
            "   - Exclusivity: If the brand requires exclusivity, meaning you won't promote any competing candle brands during the campaign period, you can factor this into your pricing.\n",
            "   - Timing and Deadlines: Consider the turnaround time for content creation and delivery. If the brand needs the videos within a tight deadline, it may impact your availability for other projects, allowing you to adjust your rates accordingly.\n",
            "\n",
            "Regarding the ballpark range to charge, it's challenging to provide an exact figure without specific details about your engagement rate, content complexity, and the brand's requirements. However, based on the research and market rates mentioned above, you could consider the following range as a starting point:\n",
            "\n",
            "- For a basic product showcase or unboxing video series with standard usage rights, you might charge between $600 to $1,500 per video, totaling $1,800 to $4,500 for three videos.\n",
            "- If the content involves more creative storytelling, behind-the-scenes footage, or exclusive usage rights, you could negotiate higher rates, ranging from $1,500 to $3,000 per video, or $4,500 to $9,000 for the entire campaign.\n",
            "\n",
            "Remember, these are rough estimates, and you should adjust your pricing based on the unique value you bring to the table and the specific terms of the collaboration. It's always a good idea to provide the brand with a detailed proposal outlining your rates, the scope of work, and any additional services or benefits they can expect from the partnership.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (Anaconda)",
      "language": "python",
      "name": "anaconda3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}