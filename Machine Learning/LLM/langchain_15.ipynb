{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anumit-web/python-interview-2024/blob/main/machine%20learning/Unsupervised_Learning_clustering_type_iris_flower_clustering_Gaussian_mixture_model_(GMM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_lhvb-UXLbF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomuVIUl9uY6"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Shee7JuzVF"
      },
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt templates\n",
        "\n",
        "# FewShotPromptTemplate - 2\n",
        "\n",
        "# ChatPromptTemplate"
      ],
      "metadata": {
        "id": "99VCqplEvvAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating PromptTemplate with LLMs"
      ],
      "metadata": {
        "id": "8XwHCnNavxns"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow1vTaKl9oHQ"
      },
      "source": [
        "# Chapter 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko4QaixAfPyF"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKa4SWV84DMv"
      },
      "source": [
        "# Python Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3pRBaqLz9atZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFXpB4wv-5-1",
        "outputId": "1a746097-9a90-4fb7-b39d-3663b7974471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0djESK29att",
        "outputId": "f414f320-c514-4879-d47c-d397da727783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello, World!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nfFMli_AEOK2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "56c27396-567f-4f55-eb49-cde7d3bfd20d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2024-11-15  08:19'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "tz = timezone('EST')\n",
        "datetime.now(tz).strftime(\"%Y-%m-%d  %H:%M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjDoARvnvU2L"
      },
      "source": [
        "---\n",
        "---\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR391vUc7l-N"
      },
      "source": [
        "# Python code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkfbOedi1WHO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1SZd9nC1wLm3"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import langchain\n",
        "except:\n",
        "  !pip install langchain\n",
        "  import langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4iCA0l5hxjB8"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-community langchain-core --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0n5IXOCNxppN"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade langchain --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -qU langchain-openai --quiet"
      ],
      "metadata": {
        "id": "_zVBLvkpHoUY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "AWiheCyd1Yc0"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-cohere --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install langchain-huggingface --quiet"
      ],
      "metadata": {
        "id": "z_eJLyvxN3ax"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "A0RW7lT_UxHE"
      },
      "outputs": [],
      "source": [
        "# ! pip install --upgrade --quiet tiktoken langchain langgraph beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "01GEQvpTUyyp"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-core langgraph>0.2.27 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Ck7bfWqemvdt"
      },
      "outputs": [],
      "source": [
        "# ! pip install langchain-huggingface --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3vL9TN8TWuj"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wEst9m_R1ZPy"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = \"Q6nIsqJ4FX9XcZwlcQLSzA06z0oXYAGBw0jmCdbE\"\n",
        "\n",
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus\")\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus-08-2024\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "openai_api_key = \"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\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm_model2 = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "llm_model2 = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "llm_model2 = ChatOpenAI(model=\"gpt-3.5-turbo\")\n"
      ],
      "metadata": {
        "id": "0fWLusbOG27J"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = \"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\"\n",
        "\n",
        "repo_id = \"tencent/Tencent-Hunyuan-Large\"\n",
        "repo_id = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "llm_model3 = HuggingFaceEndpoint(\n",
        "    repo_id=repo_id,\n",
        "    max_length=128,\n",
        "    temperature=0.5,\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvmHCzl1OQ8P",
        "outputId": "ccc59bb1-8b7e-42ef-fac9-a1fdc70c8460"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "Nv_mwGwkrlIh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqthzTFPZsvU"
      },
      "source": [
        "# Prompt tables in ChatGPT\n",
        "# we use Cohere instead of chatgpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljt5T8yPjYeq"
      },
      "source": [
        "# This is NOT working ❌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_VXS7tTjS4Y"
      },
      "source": [
        "# This is working ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "I7JxAG-Cf3A4",
        "outputId": "175f99bc-55de-4602-f749-0888c3275ac6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">10 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "count = 10\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">10 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbrN-0pu5L3I"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "count = count + 10\n",
        "counter_var = '<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">'+ str(count) + \"&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>\"\n",
        "display(HTML(counter_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "sojZoCdw59fF",
        "outputId": "ebe42850-098f-4a31-9843-b3095ba1930a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">20&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into French\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "output = llm_model.invoke(messages)\n",
        "\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPhryIPb6KOv",
        "outputId": "21e16c27-2018-401a-e16b-1a0ded55cf48"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonjour ! Comment puis-je vous aider aujourd'hui ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = count + 10\n",
        "counter_var = '<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">'+ str(count) + \"&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>\"\n",
        "display(HTML(counter_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "EF8Gliua9Hs6",
        "outputId": "77b70e17-0471-4ac3-fca6-d6bd4a79fce4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">30&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "m-ifyjPA6Fxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 Types of LangChain Prompt Templates\n",
        "When you prompt in LangChain, you’re encouraged (but not required) to use a predefined template class such as:\n",
        "\n",
        "PromptTemplate for creating basic prompts.\n",
        "FewShotPromptTemplate for few-shot learning.\n",
        "ChatPromptTemplate for modeling chatbot interactions"
      ],
      "metadata": {
        "id": "Bi2JYnpi9C8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"question\": \"What is the tallest mountain in the world?\",\n",
        "        \"answer\": \"Mount Everest\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is the largest ocean on Earth?\",\n",
        "        \"answer\": \"Pacific Ocean\"\n",
        "     },\n",
        "    {\n",
        "        \"question\": \"In which year did the first airplane fly?\",\n",
        "         \"answer\": \"1903\"\n",
        "    },\n",
        "]\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"answer\"],\n",
        "    template=\"Question: {question}\\n{answer}\",\n",
        ")\n",
        "\n",
        "prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"Question: {input}\",\n",
        "    input_variables=[\"input\"],\n",
        ")\n",
        "\n",
        "print('--------------------')\n",
        "\n",
        "\n",
        "print(\n",
        "    prompt_template.format(\n",
        "        input=\"What is the name of the famous clock tower in London?\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print('--------------------')\n",
        "\n",
        "# Formatting the prompt with new content\n",
        "formatted_prompt = prompt_template.format(\n",
        "        input=\"What is the name of the famous clock tower in London?\"\n",
        "    )\n",
        "\n",
        "output = llm_model.invoke(formatted_prompt)\n",
        "\n",
        "print(output.content)\n"
      ],
      "metadata": {
        "id": "7LiNlVwyLN-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14fe2d3-380b-476e-eb26-cfa716123883"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "Question: What is the tallest mountain in the world?\n",
            "Mount Everest\n",
            "\n",
            "Question: What is the largest ocean on Earth?\n",
            "Pacific Ocean\n",
            "\n",
            "Question: In which year did the first airplane fly?\n",
            "1903\n",
            "\n",
            "Question: What is the name of the famous clock tower in London?\n",
            "--------------------\n",
            "The famous clock tower in London is commonly known as 'Big Ben', although this is actually the name of the bell inside the tower, and not the tower itself. The tower was officially named 'Elizabeth Tower' in 2012, to mark the Diamond Jubilee of Elizabeth II. However, the nickname 'Big Ben' is still widely used to refer to the tower.\n",
            "\n",
            "The tower is an iconic landmark in London, standing at the north end of the Palace of Westminster. It was completed in 1859 and has since become one of the most recognizable symbols of the city and the United Kingdom. The clock tower features a distinctive design with a large clock face on each side and is an excellent example of Gothic Revival architecture. The clock mechanism is renowned for its reliability and accuracy, and the chimes of Big Ben are broadcast by the BBC World Service, making it one of the world's most recognizable sounds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "_J_WqtVB6LvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = count + 10\n",
        "counter_var = '<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">'+ str(count) + \"&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>\"\n",
        "display(HTML(counter_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "NUmMdR747GAP",
        "outputId": "33b908d2-933b-4609-b071-69c710791da7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">40&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = count + 10\n",
        "counter_var = '<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">'+ str(count) + \"&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>\"\n",
        "display(HTML(counter_var))"
      ],
      "metadata": {
        "id": "WkMdnrjm4R13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "9fd82673-1164-4581-b8c2-ecc1449cc820"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">50&nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = \"Q6nIsqJ4FX9XcZwlcQLSzA06z0oXYAGBw0jmCdbE\"\n",
        "\n",
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus\")\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus-08-2024\")\n",
        "\n",
        "# Define a few-shot template\n",
        "few_shot_examples = [\n",
        "    {\"input\": \"Hello, how are you?\", \"output\": \"Bonjour, comment ça va?\"},\n",
        "    {\"input\": \"Good morning!\", \"output\": \"Bonjour!\"},\n",
        "    {\"input\": \"See you later.\", \"output\": \"À plus tard.\"}\n",
        "]\n",
        "\n",
        "\n",
        "# Create the few-shot prompt template\n",
        "example_template = \"Input: {input}\\nOutput: {output}\\n\"\n",
        "example_prompt = PromptTemplate(input_variables=[\"input\", \"output\"], template=example_template)\n",
        "\n",
        "prefix = \"Translate the following English text to French:\\n\"\n",
        "suffix = \"Input: {text}\\nOutput:\"\n",
        "\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=few_shot_examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "print('--------------------')\n",
        "\n",
        "# Formatting the prompt with new content\n",
        "formatted_prompt = few_shot_prompt.format(\n",
        "        text=\"Have a nice day!\"\n",
        "    )\n",
        "\n",
        "output = llm_model.invoke(formatted_prompt)\n",
        "\n",
        "print(output.content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eLZEyBZf4S-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b2c5d4-aae4-4d29-bf49-4237a9f15961"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "Bonne journée !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = \"Q6nIsqJ4FX9XcZwlcQLSzA06z0oXYAGBw0jmCdbE\"\n",
        "\n",
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus\")\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus-08-2024\")\n",
        "\n",
        "few_shot_examples = [\n",
        "    {\n",
        "        \"input\": \"What is the tallest mountain in the world?\",\n",
        "        \"output\": \"Mount Everest\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"What is the largest ocean on Earth?\",\n",
        "        \"output\": \"Pacific Ocean\"\n",
        "     },\n",
        "    {\n",
        "        \"input\": \"In which year did the first airplane fly?\",\n",
        "         \"output\": \"1903\"\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "# Create the few-shot prompt template\n",
        "example_template = \"Input: {input}\\nOutput: {output}\\n\"\n",
        "example_prompt = PromptTemplate(input_variables=[\"input\", \"output\"], template=example_template)\n",
        "\n",
        "prefix = \"Answer the following:\\n\"\n",
        "suffix = \"Input: {text}\\nOutput:\"\n",
        "\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=few_shot_examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"text\"]\n",
        ")\n",
        "\n",
        "print('--------------------')\n",
        "\n",
        "# Formatting the prompt with new content\n",
        "formatted_prompt = few_shot_prompt.format(\n",
        "        text=\"What is the name of the famous clock tower in London?\"\n",
        "    )\n",
        "\n",
        "output = llm_model.invoke(formatted_prompt)\n",
        "\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kChunWw_d0g",
        "outputId": "1060d685-83de-4a27-8597-e32226f7c2f3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "Big Ben.\n",
            "\n",
            "Would you like to know more about any of these topics? I can provide additional information and fun facts if you wish!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (Anaconda)",
      "language": "python",
      "name": "anaconda3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}