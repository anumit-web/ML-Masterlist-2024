{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anumit-web/python-interview-2024/blob/main/machine%20learning/Unsupervised_Learning_clustering_type_iris_flower_clustering_Gaussian_mixture_model_(GMM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_lhvb-UXLbF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomuVIUl9uY6"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Shee7JuzVF"
      },
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3tkmTLuixNd"
      },
      "source": [
        "# HuggingFace introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow1vTaKl9oHQ"
      },
      "source": [
        "# Chapter 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko4QaixAfPyF"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JolABC6StbU4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Aq3-L4F4V5H"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1DHqE-Kh6H3"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ-8TePAt4oW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKa4SWV84DMv"
      },
      "source": [
        "# Python Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3pRBaqLz9atZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFXpB4wv-5-1",
        "outputId": "d2fe5e50-0829-46e1-8d59-1c35823a1aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0djESK29att",
        "outputId": "f00c4e3a-3a84-4bcd-dc6e-852c314d2774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello, World!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nfFMli_AEOK2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjDoARvnvU2L"
      },
      "source": [
        "---\n",
        "---\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR391vUc7l-N"
      },
      "source": [
        "# Python code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkfbOedi1WHO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1SZd9nC1wLm3"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import langchain\n",
        "except:\n",
        "  !pip install langchain\n",
        "  import langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4iCA0l5hxjB8"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-community langchain-core --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0n5IXOCNxppN"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade langchain --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AWiheCyd1Yc0"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-cohere --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "A0RW7lT_UxHE"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade --quiet tiktoken langchain langgraph beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "01GEQvpTUyyp"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-core langgraph>0.2.27 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ck7bfWqemvdt"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-huggingface --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3vL9TN8TWuj"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wEst9m_R1ZPy"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"] = \"Q6nIsqJ4FX9XcZwlcQLSzA06z0oXYAGBw0jmCdbE\"\n",
        "\n",
        "from langchain_cohere import ChatCohere\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus\")\n",
        "\n",
        "llm_model = ChatCohere(model=\"command-r-plus-08-2024\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqthzTFPZsvU"
      },
      "source": [
        "# Hugging Face models in LangChain!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljt5T8yPjYeq"
      },
      "source": [
        "# This is NOT working ❌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_VXS7tTjS4Y"
      },
      "source": [
        "# This is working ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "I7JxAG-Cf3A4",
        "outputId": "49ee7a15-631d-4fbe-a1e2-bc987c6f4d65"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">10 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">10 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOQ5VpBMf0p7",
        "outputId": "ffd66472-bdd4-4f27-c916-90a841dfd783"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hello Bob, I'm Command. How can I help you today?\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '1fc059d1-4e37-4ac2-b5e1-c489f4ac2e06', 'token_count': {'input_tokens': 211.0, 'output_tokens': 14.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '1fc059d1-4e37-4ac2-b5e1-c489f4ac2e06', 'token_count': {'input_tokens': 211.0, 'output_tokens': 14.0}}, id='run-7f9b060f-5b26-460e-8b2a-df94e06245b7-0', usage_metadata={'input_tokens': 211, 'output_tokens': 14, 'total_tokens': 225})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "llm_model.invoke([HumanMessage(content=\"Hi! I'm Bob\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "A48k1GtKf2fZ",
        "outputId": "2847acd8-84f0-465a-f15e-a19cb0f10d15"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">20 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">20 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZCzGm1Oo5Ex",
        "outputId": "a5f7a22e-ba7e-4338-9758-b9326c730f26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Sure, here\\'s a joke for you:\\n\\nWhy did the data scientist become a detective?\\nBecause they wanted to find the \"mean\" and \"classify\" the culprit!\\n\\nFeel free to ask for more jokes if you\\'re in need of a laugh!', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '77c866c3-73ed-481d-a95b-3c6d56601711', 'token_count': {'input_tokens': 213.0, 'output_tokens': 55.0}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '77c866c3-73ed-481d-a95b-3c6d56601711', 'token_count': {'input_tokens': 213.0, 'output_tokens': 55.0}}, id='run-fca24e39-0db6-4742-a498-8204940cd148-0', usage_metadata={'input_tokens': 213, 'output_tokens': 55, 'total_tokens': 268})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "llm_model.invoke([HumanMessage(content=\"Tell me a joke about data scientist\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSOTr5G823HI"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vm90Ho2Xi1qO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "e8682347-e86a-4e08-8789-e8f5a3d81465"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">50 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML('<p style=\"color:#DE0000;font-size:60px;font-weight: 900;\">50 &nbsp; &nbsp;  &nbsp; &nbsp; &#8595;</p>'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN4h4fnw26j_",
        "outputId": "9e986873-ac5c-4a1b-8b3a-2b79670ff9e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            " when it's cold?\n",
            "Yes, you can still have fun when it's cold! There are plenty of indoor activities you can do, such as playing board games or video games, curling up with a good book, or even going on a hot chocolate date. You can also go on outdoor activities like skiing, snowboarding, or even ice fishing if you're feeling adventurous. The cold weather can actually be a great opportunity to get creative with your entertainment options and have a fun time without spending a lot of money!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "llm_model = HuggingFaceEndpoint(\n",
        "     repo_id='tiiuae/falcon-7b-instruct',\n",
        "     huggingfacehub_api_token=\"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\"\n",
        "     #add_to_git_credential: bool = False\n",
        "\n",
        ")\n",
        "\n",
        "question = 'Can you still have fun'\n",
        "output = llm_model.invoke(question)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d9BgjVei01c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbrN-0pu5L3I"
      },
      "source": [
        "---\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (Anaconda)",
      "language": "python",
      "name": "anaconda3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}